/**
 * \file test_rng.c
 * \brief Random Number Generator Statistical Tests.
 *
 * Files here are inspired from «Beatuful Testing», § 10, where a few of the
 * most common methods for testing a random number generator are analyzed:
 * - range test
 * - mean test
 * - variance test
 * - bucket test
 * - Kolmogorov-Smirnov test
 *
 *
 * NIST SP800-22 (1a)
 * NIST SP800-90 (a: block cipher as rng,
 *                b: correlation,
 *                c)
 * NIST test suite sts 2.1.1
 * test u01
 */

#include <assert.h>
#include <stdio.h>
#include <math.h>
#include <limits.h>
#include <stdint.h>
#include <string.h>

#include <gsl/gsl_statistics.h>
#include "rng.h"


#define DSIZE 500
const size_t n = DSIZE;

double fdataset[DSIZE];
double sdataset[DSIZE];

/**
 * we expect the sample mean 𝔼[fdataset] to match the mean μ of a uniform
 * distribution.
 */
double mean;
double sd;
size_t elems;

void set_up(void)
{
  const char* dummy_seed = "seed";
  char rnd_stream[DSIZE];
  size_t i;

  /* initialize fast random number gerator */
  frng(rnd_stream, dummy_seed, n);
  for (i=0; i!=DSIZE; i++)
    fdataset[i] = (unsigned char) rnd_stream[i];

  /* initialize system random number generator */
  FILE *devrandom = fopen("/dev/urandom", "r");
  for (i=0; i!=DSIZE; i++)
    fdataset[i] = (unsigned char) fgetc(devrandom);
  fclose(devrandom);

  /* initalize secure random generator */
  srng(rnd_stream, dummy_seed, n);
  for (i=0; i!=DSIZE; i++)
    sdataset[i] = (unsigned char) rnd_stream[i];

  /* set dsitribution mean, and variance. */
  elems = 256;
  mean = elems / 2;
  sd = sqrt(pow(elems-1, 2) / 12);

}

/**
 * \brief range test.
 *
 * Considering a random number generator producing numbers between a and b, each
 * extracted number is in the range [a, b].
 *
 */
void test_range(double* dataset)
{
  /* the random number generator, as it is now, generates numbers always a c s.t.
   * c ∈ {0, …, 0xff} ≡ char
   */
  double sum;
  size_t i;


  for (i=sum=0; i!=n; i++) {
    assert(dataset[i] >= 0 &&
           dataset[i] < elems);
    sum += dataset[i];
  }

  assert(sum);
}

/**
 * \brief mean test.
 *
 * «In summary, the way to test samples from a normal random number generator
 *  with mean μ and standard deviation σ is to average n values for some large
 *  value of n, say n = 106. Then look for the average to be between μ − 2σ/√n
 *  and μ + 2σ/√n around 95% of the time, or between μ − 3σ/√n and μ + 3σ/√n
 *  around 99.7% of the time.»
 *
 */
void test_mean(double* dataset)
{
  double sampled_mean;
  double a, b;

  sampled_mean = gsl_stats_mean(dataset, 1, n);

  a = mean - 2*sd/sqrt(n);
  b = mean + 2*sd/sqrt(n);
  assert(sampled_mean > a && sampled_mean < b);
}


/**
 * \brief variance test.
 *
 * «Let S² be the sample variance based on n values from the RNG. If n is very
 *  large, then S² approximately has a normal distribution with mean σ² and
 *  variance 2σ⁴/(n−1).As before, we apply the idea that anything with a normal
 *  distribution will lie within two standard deviations of its mean 95% of the
 *  time.»
 */
void test_variance(double* dataset)
{
  double sampled_vr;
  double sampled_vr_mean, sampled_vr_sd;
  double a, b;

  /*
   * we expect the sampled standard deviation S to match the standard deviation
   * σ of a uniform distribution
   */
  sampled_vr = gsl_stats_variance(dataset, 1, n);
  sampled_vr_mean = pow(sd, 2);
  sampled_vr_sd = sqrt(2 * pow(sd, 4) / (n - 1));

  a = sampled_vr_mean - 2*sampled_vr_sd;
  b = sampled_vr_mean + 2*sampled_vr_sd;
  assert(sampled_vr > a && sampled_vr < b);
}


/**
 * \brief χ² test
 *
 * Divide the whole range of values potentially generated by the Random Number
 * Generator into n buckets,
 *
 *   B = {B₀, …, Bₙ} | ∀ Bᵢ,Bⱼ ∈ B, Bᵢ∩Bⱼ = ∅
 *
 * As a rule of thumb, n ≥ 5.
 * Then, given Eᵢ the expected number of samples for Bᵢ,
 * and   given Oᵢ the observed number of samples for Bᵢ,
 * <pre>
 *       ₙ    (Oᵢ - Eᵢ)²
 *  χ² = ∑   ―――――――――――
 *       ⁱ       Eᵢ
 * </pre>
 * The statistic χ² has a chi-squared sitribution with n-1 degrees of freedom
 * that, for a sufficiently large `elems`, can be approximated to a normal
 * distribution N(n-1, 2n-2). Then we can use the same rules as before regarding
 * how often a normal random variable is within two or three standard deviations
 * of its mean.
 *
 */
void test_bucket(double* dataset)
{
  const size_t buckets = 64;
  const double expected = (double) n / buckets;
  const double step = (double) elems / buckets;
  unsigned int observed[buckets];
  double chisq;
  size_t i, j;
  double a, b;

  bzero(observed, sizeof(unsigned int) * buckets);
  for (i=0; i!=n; i++) {
    for (j=1; dataset[i] > step*j && j <= buckets; j++);
    observed[j-1]++;
  }

  for (i=chisq=0; i!=buckets; i++)
    chisq += pow(observed[i] - expected, 2) / expected;

  /* Assuming the space gets equally divided into `buckets` buckets of `step` ranges. */
  a = buckets-1 - 2*sqrt(2*buckets - 2);
  b = buckets-1 + 2*sqrt(2*buckets - 2);
  assert(chisq > a && chisq < b);
}


/**
 * \brief uniform comulative probabiility distribution.
 *
 * The discrete uniform distribution is defined as:
 * <pre>
 *
 *                ⌊k⌋ - a + 1
 *  F(k; a,b) =  ―――――――――――――
 *                 b - a + 1
 * </pre>
 * Assuming that our range of values is a = 0, b = 255, follows the
 *  implementation.
 */
static double uniform_distribution(double k)
{
  return (floor(k) + 1) / (255 + 1);
}

static double empirical_distribution(double k, double* dataset)
{
  size_t i;
  double f = .0;

  for (i=0; i!=n; i++)
    if (dataset[i] <= k) f++;
  return f / n;
}

/**
 * \brief Kolmogorov–Smirnov test
 *
 * Kolmogorov-Smirnov test calculates the dinstance between the empirical
 * distribution and the theoretical cumulative disltribution fucntion. Hence,
 * given the empirical distribution as
 * <pre>
 *  Fₙ(x) = |{xᵢ . xᵢ ∈ dataset, xᵢ ≤ x}| / n
 * </pre>
 * and the theoretical distribution F(x) = P(X < x), where P is the
 * predetermined ideal probability distribution of the random variable, let:
 * <pre>
 *
 *   K⁺ = √n max (Fₙ(x) - F(x))
 *   K⁻ = √n max (F(x) - Fₙ(x))
 *
 * </pre>
 * Accordig to `The Art of Computer Programming`, Vol. 2, § Seminumerical
 * Algorithms, K⁺ ∈ [0.07089, 1.5174].
 */
void test_ks(double* dataset)
{
  double kplus;
  /* double kminus; */
  double x;

  for (x=0.; x<255; x+=0.5)
    kplus = fmax(kplus,
                 empirical_distribution(x, dataset)-uniform_distribution(x));
  kplus = kplus * sqrt(n);

  assert(kplus > 0.07089 &&
         kplus < 1.5174);
}

int main(int argc, char** argv)
{
  set_up();

  test_range(fdataset);
  test_mean (fdataset);
  test_variance(fdataset);
  test_bucket(fdataset);
  test_ks(fdataset);

  test_range(sdataset);
  test_mean(sdataset);
  test_variance(sdataset);
  test_bucket(sdataset);
  test_ks(sdataset);

  return 0;
}
